{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q06i7Vql8H4P"
   },
   "source": [
    "# FeeBee\n",
    "\n",
    "This colab is used to compare BER estimator on real world data. The csv files imported were generated using the FeeBee framework (https://github.com/DS3Lab/feebee). This colab merely uses the csv files generated by the framework and stored in GDrive to visualize the results in plots and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ViDg0nNZofL"
   },
   "outputs": [],
   "source": [
    "methods_to_evaluate = [\n",
    "    \"kde_knn_loo\",\n",
    "    \"ghp\",\n",
    "    \"kde\",\n",
    "    \"knn\",\n",
    "    \"1nn\",\n",
    "    \"knn_extrapolate\",\n",
    "    \"knn_loo\",\n",
    "    \"onenn\",\n",
    "]\n",
    "\n",
    "download_pre_computed_files = False  # Set to true to use the pre-computed files from GDrive. Attention: This will overwrite your local files!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCTrRBHu_khJ"
   },
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXk73WLv8b5X"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ulk9OAc6pEW"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "sns.set(font=\"DejaVu Sans\", context=\"paper\", style=\"whitegrid\", font_scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVULQ8Dt8dk7"
   },
   "source": [
    "### Download csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9P4xw1ti8HJY",
    "outputId": "a01abf0d-405a-48c8-85e2-fe350d421694"
   },
   "outputs": [],
   "source": [
    "if download_pre_computed_files:\n",
    "    !wget -q --show-progress --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zAQEWV8lMmtgL6gyTwYV2iAPDajRDiFd' -O analysis.csv\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1yL86br4WclgZ9KiL1LzEKx1QVWgVHId1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1yL86br4WclgZ9KiL1LzEKx1QVWgVHId1\" -O results.csv && rm -rf /tmp/cookies.txt\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11p1XBJLdyA_UUp4XUI9LKnxw3e-UZ-ro' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11p1XBJLdyA_UUp4XUI9LKnxw3e-UZ-ro\" -O areas.csv && rm -rf /tmp/cookies.txt\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11p1XBJLdyA_UUp4XUI9LKnxw3e-UZ-ro' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11p1XBJLdyA_UUp4XUI9LKnxw3e-UZ-ro\" -O areas.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtEZwHrxrJL2",
    "outputId": "6835511e-5b11-44f2-956c-dfea335e7722"
   },
   "outputs": [],
   "source": [
    "if download_pre_computed_files:\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=105gImOyuy0W0DYDUp4SOZ5vtg0JM9m7P' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=105gImOyuy0W0DYDUp4SOZ5vtg0JM9m7P\" -O areas_0.75.csv && rm -rf /tmp/cookies.txt\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=12lBAnBUewBCTjKIYPQgM0A95PtlAtYAR' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=12lBAnBUewBCTjKIYPQgM0A95PtlAtYAR\" -O areas_0.90.csv && rm -rf /tmp/cookies.txt\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1PmO-gYAVqpOfjo3vDPCg31cD2dCg45rM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1PmO-gYAVqpOfjo3vDPCg31cD2dCg45rM\" -O areas_0.95.csv && rm -rf /tmp/cookies.txt\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1nzDDyhA4YD5rURubryMxs7wbmPPzo7uS' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1nzDDyhA4YD5rURubryMxs7wbmPPzo7uS\" -O areas_1.05.csv && rm -rf /tmp/cookies.txt\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1W-ZXEV-3ekYuP4HAlVtQOK0_tOV8NYQE' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1W-ZXEV-3ekYuP4HAlVtQOK0_tOV8NYQE\" -O areas_1.10.csv && rm -rf /tmp/cookies.txt\n",
    "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1uXmzvqZ2q73tlbhJBoVL77CryLlg1hUK' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1uXmzvqZ2q73tlbhJBoVL77CryLlg1hUK\" -O areas_1.25.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_a3Zzkr_gz7"
   },
   "source": [
    "### Read data to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYQFFhtK8ui8"
   },
   "outputs": [],
   "source": [
    "df_analysis = pd.read_csv(\"analysis.csv\")\n",
    "df_analysis = df_analysis[df_analysis.dataset.isin(config.keys())]\n",
    "df_analysis.drop(columns=df_analysis.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpDlNolw_p8P"
   },
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(\"results.csv\")\n",
    "df_results = df_results[df_results.dataset.isin(config.keys())]\n",
    "df_results.drop(columns=df_results.columns[0], axis=1, inplace=True)\n",
    "df_results[\"results\"] = df_results.results.apply(\n",
    "    lambda x: [float(z) for z in x[1:-1].split(\", \")]\n",
    "    if x.startswith(\"[\")\n",
    "    else [float(x)]\n",
    ")\n",
    "\n",
    "\n",
    "# Get transformation from identifier\n",
    "def split_identifiers(x):\n",
    "    for v in [\"_l2_\", \"_beta_\", \"_measure_\"]:\n",
    "        if v in x:\n",
    "            x = x.split(v)[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "df_results[\"transformation\"] = df_results.identifier.apply(split_identifiers)\n",
    "\n",
    "# Split into upper and lower\n",
    "df_results[\"value\"] = df_results.results.apply(lambda x: x[0])\n",
    "df_results[\"value_type\"] = \"upperbound\"\n",
    "\n",
    "scaling_constant = 0.95\n",
    "cp_df = df_results.copy()\n",
    "cp_df[\"value\"] = cp_df.results.apply(\n",
    "    lambda x: x[1] if len(x) > 1 else x[0] * scaling_constant\n",
    ")\n",
    "cp_df[\"value_type\"] = \"lowerbound\"\n",
    "\n",
    "df_results = pd.concat([df_results, cp_df], ignore_index=True)\n",
    "\n",
    "# Add 1NN\n",
    "cp_df = df_results[\n",
    "    (df_results.method == \"knn\") & (df_results.variant.str.endswith(\", k=1\"))\n",
    "].copy()\n",
    "\n",
    "cp_df[\"method\"] = \"1nn\"\n",
    "cp_df[\"variant\"] = cp_df.variant.apply(lambda x: x[: -len(\", k=1\")])\n",
    "\n",
    "df_results = pd.concat([df_results, cp_df], ignore_index=True)\n",
    "\n",
    "# Change LR and add other constant\n",
    "df_results[\"method\"] = df_results.method.apply(\n",
    "    lambda x: x if x != \"lr_model\" else f\"lr_model_{scaling_constant}\"\n",
    ")\n",
    "\n",
    "scaling_constant = 0.8\n",
    "cp_df = df_results[\n",
    "    (df_results.method.str.startswith(\"lr_model\"))\n",
    "    & (df_results.value_type == \"upperbound\")\n",
    "].copy()\n",
    "cp_df[\"method\"] = f\"lr_model_{scaling_constant}\"\n",
    "\n",
    "cp_df2 = cp_df.copy()\n",
    "cp_df2[\"value\"] = cp_df2.results.apply(\n",
    "    lambda x: x[1] if len(x) > 1 else x[0] * scaling_constant\n",
    ")\n",
    "cp_df2[\"value_type\"] = \"lowerbound\"\n",
    "df_results = pd.concat([df_results, cp_df, cp_df2], ignore_index=True)\n",
    "\n",
    "# Set label\n",
    "df_results[\"label\"] = (\n",
    "    df_results.method + \"/\" + df_results.variant + \"/\" + df_results.transformation\n",
    ")\n",
    "\n",
    "# DROP NaNs\n",
    "df_results.dropna(subset=[\"value\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gokUHIveTzax"
   },
   "outputs": [],
   "source": [
    "df_areas = pd.read_csv(\"areas.csv\")\n",
    "df_areas = df_areas[df_areas.dataset.isin(config.keys())]\n",
    "df_areas.drop(columns=df_areas.columns[0], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Rescale areas to lies between 0 and 1\n",
    "def update_area(row, column):\n",
    "    classes = config[row[\"dataset\"]][\"classes\"]\n",
    "    return row[column] * ((2 * classes) / (classes - 1))\n",
    "\n",
    "\n",
    "for column in [\"eu_top\", \"eu_bottom\", \"eu_sum\", \"el_top\", \"el_bottom\", \"el_sum\"]:\n",
    "    df_areas[column] = df_areas.apply(lambda row: update_area(row, column), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqAME99ar_br"
   },
   "outputs": [],
   "source": [
    "df_areas_factors = {}\n",
    "\n",
    "for factor in [\"0.75\", \"0.90\", \"0.95\", \"1.05\", \"1.10\", \"1.25\"]:\n",
    "    df_current = pd.read_csv(f\"areas_{factor}.csv\")\n",
    "    df_current = df_current[df_current.dataset.isin(config.keys())]\n",
    "    df_current.drop(columns=df_current.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    # Rescale areas to lies between 0 and 1\n",
    "    def update_area(row, column):\n",
    "        classes = config[row[\"dataset\"]][\"classes\"]\n",
    "        return row[column] * ((2 * classes) / (classes - 1))\n",
    "\n",
    "    for column in [\"eu_top\", \"eu_bottom\", \"eu_sum\", \"el_top\", \"el_bottom\", \"el_sum\"]:\n",
    "        df_current[column] = df_current.apply(\n",
    "            lambda row: update_area(row, column), axis=1\n",
    "        )\n",
    "\n",
    "    df_areas_factors[factor] = df_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvxjwdHLXkzQ"
   },
   "source": [
    "## Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCq64j48Xm29"
   },
   "outputs": [],
   "source": [
    "def shorten_variant(variant):\n",
    "    variant = variant.replace(\"kernel=gaussian, \", \"\")\n",
    "    variant = variant.replace(\"bandwidth=\", \"B=\")\n",
    "    variant = variant.replace(\"measure=\", \"dist=\")\n",
    "    return variant\n",
    "\n",
    "\n",
    "def readble_method(method):\n",
    "    if method.startswith(\"lr_model\"):\n",
    "        val = float(method.split(\"_\")[-1])\n",
    "        return f\"LR ({val})\"\n",
    "    mapping = {\n",
    "        \"kde_knn_loo\": \"DE-kNN\",\n",
    "        \"ghp\": \"GHP\",\n",
    "        \"kde\": \"Gaussian KDE\",\n",
    "        \"knn\": \"kNN\",\n",
    "        \"1nn\": \"1NN\",\n",
    "        \"knn_extrapolate\": \"kNN_Extrapolate\",\n",
    "        \"knn_loo\": \"kNN-LOO\",\n",
    "        \"onenn\": \"1NN-kNN\",\n",
    "    }\n",
    "    return mapping[method]\n",
    "\n",
    "\n",
    "def readble_transformation(transformation):\n",
    "    for remove in [\"_pt\", \"_tf\"]:\n",
    "        transformation = transformation.replace(remove, \"\")\n",
    "\n",
    "    mapping = {\n",
    "        # VISION\n",
    "        \"alexnet\": \"AlexNet\",\n",
    "        \"googlenet\": \"GoogleNet\",\n",
    "        \"inception_v3\": \"InceptionV3\",\n",
    "        \"raw\": \"Raw\",\n",
    "        # NLP\n",
    "        \"bert\": \"BERT\",\n",
    "        \"bow\": \"BOW\",\n",
    "        \"bowidf\": \"BOW-TFIDF\",\n",
    "        \"elmo\": \"ELMO\",\n",
    "        \"use\": \"USE\",\n",
    "    }\n",
    "\n",
    "    if transformation in mapping.keys():\n",
    "        return mapping[transformation]\n",
    "\n",
    "    if \"pca_\" in transformation:\n",
    "        l = len(\"pca_\")\n",
    "        return f\"PCA (d={transformation[l:]})\"\n",
    "\n",
    "    # VISION\n",
    "    if \"efficientnet\" in transformation:\n",
    "        return f\"EfficientNet-B{transformation[-1]}\"\n",
    "    if \"nca\" in transformation:\n",
    "        return f\"NCA (d={transformation[-2:]})\"\n",
    "    if \"resetnet_v2_\" in transformation:\n",
    "        l = len(\"resetnet_v2_\")\n",
    "        return f\"ResNet{transformation[l:]}-V2\"\n",
    "    if \"vgg\" in transformation:\n",
    "        return f\"VGG{transformation[-2:]}\"\n",
    "\n",
    "    # NLP\n",
    "    if \"nnlm\" in transformation and \"_norm\" in transformation:\n",
    "        val = transformation[: -len(\"_norm\")][len(\"nnlm\") :]\n",
    "        return f\"NNLM-EN-NORM (d={val})\"\n",
    "    if \"nnlm\" in transformation:\n",
    "        val = transformation[len(\"nnlm\") :]\n",
    "        return f\"NNLM-EN (d={val})\"\n",
    "\n",
    "    return transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9a-7a863OvK"
   },
   "source": [
    "## Number of runs (success / failed / timed out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NoDgFEp3T9g",
    "outputId": "de846029-cab1-4798-ee9f-bc34faf3a5f0"
   },
   "outputs": [],
   "source": [
    "print(\"Total number of runs: {}\".format(df_analysis.count()[0]))\n",
    "print(\"Out of memory: {}\".format(df_analysis[df_analysis.status == \"ERROR\"].count()[0]))\n",
    "print(\"Timed out: {}\".format(df_analysis[df_analysis.status == \"TIMEOUT\"].count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8qJpZC5WnCN"
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyDs8iG3mQKY"
   },
   "outputs": [],
   "source": [
    "fig_folder = \"figures\"\n",
    "if not path.exists(fig_folder):\n",
    "    os.mkdir(fig_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHxl78y-Xwd-"
   },
   "source": [
    "### Style and common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyvsO7HmWdx3"
   },
   "outputs": [],
   "source": [
    "dash_list = sns._core.unique_dashes(2)\n",
    "dashes = {\n",
    "    \"upperbound\": dash_list[0],\n",
    "    \"lowerbound\": dash_list[1],\n",
    "}\n",
    "\n",
    "palette = {}\n",
    "for i, m in enumerate(methods_to_evaluate):\n",
    "    palette[readble_method(m)] = f\"C{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgaPgn93SAry"
   },
   "outputs": [],
   "source": [
    "def plot_single_axis(\n",
    "    ax,\n",
    "    dataset,\n",
    "    methods,\n",
    "    variants,\n",
    "    transformations,\n",
    "    ci=None,\n",
    "    labels_src=\"method\",\n",
    "    label_fn=readble_method,\n",
    "    value_type=None,\n",
    "    use_palet=None,\n",
    "):\n",
    "    classes = config[dataset][\"classes\"]\n",
    "    sota = config[dataset][\"sota\"]\n",
    "\n",
    "    def filter_fn(row):\n",
    "        for i, m in enumerate(methods):\n",
    "            if (\n",
    "                (row.method == m)\n",
    "                and (row.transformation == transformations[i])\n",
    "                and (row.variant == variants[i])\n",
    "            ):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    filtered_df = df_results[\n",
    "        (df_results.dataset == dataset)\n",
    "        & (df_results.method.isin(methods))\n",
    "        & (df_results.transformation.isin(transformations))\n",
    "        & (df_results.variant.isin(variants))\n",
    "    ]\n",
    "\n",
    "    if value_type:\n",
    "        filtered_df = filtered_df[filtered_df.value_type == value_type]\n",
    "\n",
    "    filtered_df = filtered_df[filtered_df.apply(filter_fn, axis=1)].copy()\n",
    "\n",
    "    filtered_df.label = filtered_df[labels_src].map(label_fn)\n",
    "\n",
    "    x = [x / float(10) for x in range(11)]\n",
    "    y_true_upper = [sota + val * ((classes - 1.0) / classes - sota) for val in x]\n",
    "    trivial_lower = 0.0\n",
    "    y_true_lower = [\n",
    "        trivial_lower + val * ((classes - 1.0) / classes - trivial_lower) for val in x\n",
    "    ]\n",
    "\n",
    "    if (use_palet is None and labels_src == \"method\") or use_palet:\n",
    "        sns.lineplot(\n",
    "            ax=ax,\n",
    "            data=filtered_df,\n",
    "            x=\"noise\",\n",
    "            y=\"value\",\n",
    "            hue=\"label\",\n",
    "            style=\"value_type\",\n",
    "            dashes=dashes,\n",
    "            ci=ci,\n",
    "            linewidth=3,\n",
    "            alpha=0.7,\n",
    "            palette=palette,\n",
    "        )\n",
    "    else:\n",
    "        sns.lineplot(\n",
    "            ax=ax,\n",
    "            data=filtered_df,\n",
    "            x=\"noise\",\n",
    "            y=\"value\",\n",
    "            hue=\"label\",\n",
    "            style=\"value_type\",\n",
    "            dashes=dashes,\n",
    "            ci=ci,\n",
    "            linewidth=3,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "    sns.lineplot(ax=ax, x=x, y=y_true_upper)\n",
    "    sns.lineplot(ax=ax, x=x, y=y_true_lower)\n",
    "    ax.lines[-2].set_color(\"Gray\")\n",
    "    ax.lines[-1].set_color(\"Gray\")\n",
    "    ax.lines[-1].set_linestyle(\"--\")\n",
    "    ax.set_xlabel(r\"Label noise $\\rho$\")\n",
    "    ax.set_ylabel(\"Estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqmpl0OyRzBG"
   },
   "source": [
    "### Custom examples of comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "qc3tuLuDRyuS",
    "outputId": "735e220e-fc9b-434a-9f75-f9e2b2728ccb"
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "# CONFIG 1\n",
    "dataset = \"mnist\"\n",
    "methods = [\"1nn\", \"kde\"]\n",
    "variants = [\"measure=cosine\", \"kernel=gaussian, bandwidth=0.05\"]\n",
    "transformations = [\"nca_64\", \"vgg16_pt\"]\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"MNIST - Optim. $L_\\mathcal{D}$\")\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.set_ylim(0, 0.91)\n",
    "\n",
    "plot_single_axis(\n",
    "    ax, dataset, methods, variants, transformations, ci=95, value_type=\"lowerbound\"\n",
    ")\n",
    "\n",
    "# Get values for L_D method 1\n",
    "val = (\n",
    "    df_areas[\n",
    "        (df_areas.dataset == dataset)\n",
    "        & (df_areas.method == methods[0])\n",
    "        & (df_areas.variant == variants[0])\n",
    "        & (df_areas.transformation == transformations[0])\n",
    "    ]\n",
    "    .iloc[0]\n",
    "    .el_sum\n",
    ")\n",
    "ax.annotate(\n",
    "    \"$L_\\mathcal{{D}}={0:.2f}$\".format(val),\n",
    "    xy=(0.38, 0.35),\n",
    "    xytext=(0.3, 0.1),\n",
    "    arrowprops=dict(\n",
    "        facecolor=palette[readble_method(methods[0])], alpha=1.0, shrink=0.05\n",
    "    ),\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "# Get values for L_D method 2\n",
    "val = (\n",
    "    df_areas[\n",
    "        (df_areas.dataset == dataset)\n",
    "        & (df_areas.method == methods[1])\n",
    "        & (df_areas.variant == variants[1])\n",
    "        & (df_areas.transformation == transformations[1])\n",
    "    ]\n",
    "    .iloc[0]\n",
    "    .el_sum\n",
    ")\n",
    "ax.annotate(\n",
    "    \"$L_\\mathcal{{D}}={0:.2f}$\".format(val),\n",
    "    xy=(0.68, 0.52),\n",
    "    xytext=(0.7, 0.3),\n",
    "    arrowprops=dict(\n",
    "        facecolor=palette[readble_method(methods[1])], alpha=1.0, shrink=0.05\n",
    "    ),\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "handles, lables = ax.get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "    h.set_linestyle(\"dashed\")\n",
    "ax.legend(handles[1 : 1 + len(methods)], lables[1 : 1 + len(methods)])\n",
    "\n",
    "# CONFIG 2\n",
    "dataset = \"imdb\"\n",
    "methods = [\"knn_loo\", \"onenn\"]\n",
    "variants = [\"measure=squared_l2, k=1\", \"measure=cosine, k=4\"]\n",
    "transformations = [\"use\", \"pca_32\"]\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"IMDB - Optim. $L_\\mathcal{D}$\")\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.set_ylim(0, 0.51)\n",
    "\n",
    "plot_single_axis(\n",
    "    ax, dataset, methods, variants, transformations, ci=95, value_type=\"lowerbound\"\n",
    ")\n",
    "\n",
    "# Get values for L_D method 1\n",
    "val = (\n",
    "    df_areas[\n",
    "        (df_areas.dataset == dataset)\n",
    "        & (df_areas.method == methods[0])\n",
    "        & (df_areas.variant == variants[0])\n",
    "        & (df_areas.transformation == transformations[0])\n",
    "    ]\n",
    "    .iloc[0]\n",
    "    .el_sum\n",
    ")\n",
    "ax.annotate(\n",
    "    \"$L_\\mathcal{{D}}={0:.2f}$\".format(val),\n",
    "    xy=(0.21, 0.18),\n",
    "    xytext=(0.3, 0.05),\n",
    "    arrowprops=dict(\n",
    "        facecolor=palette[readble_method(methods[0])], alpha=1.0, shrink=0.05\n",
    "    ),\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "# Get values for L_D method 2\n",
    "val = (\n",
    "    df_areas[\n",
    "        (df_areas.dataset == dataset)\n",
    "        & (df_areas.method == methods[1])\n",
    "        & (df_areas.variant == variants[1])\n",
    "        & (df_areas.transformation == transformations[1])\n",
    "    ]\n",
    "    .iloc[0]\n",
    "    .el_sum\n",
    ")\n",
    "ax.annotate(\n",
    "    \"$L_\\mathcal{{D}}={0:.2f}$\".format(val),\n",
    "    xy=(0.8, 0.35),\n",
    "    xytext=(0.7, 0.2),\n",
    "    arrowprops=dict(\n",
    "        facecolor=palette[readble_method(methods[1])], alpha=1.0, shrink=0.05\n",
    "    ),\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "handles, lables = ax.get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "    h.set_linestyle(\"dashed\")\n",
    "ax.legend(handles[1 : 1 + len(methods)], lables[1 : 1 + len(methods)])\n",
    "\n",
    "# CONFIG 3\n",
    "dataset = \"cifar100\"\n",
    "methods = [\"ghp\", \"knn_extrapolate\"]\n",
    "variants = [\"default\", \"measure=cosine, k=7\"]\n",
    "transformations = [\"efficientnet_b7_tf\", \"pca_32\"]\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"CIFAR100 - Optim. $U_\\mathcal{D}$\")\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.set_ylim(0, 1.0)\n",
    "\n",
    "plot_single_axis(\n",
    "    ax, dataset, methods, variants, transformations, ci=95, value_type=\"upperbound\"\n",
    ")\n",
    "\n",
    "# Get values for L_D method 1\n",
    "val = (\n",
    "    df_areas[\n",
    "        (df_areas.dataset == dataset)\n",
    "        & (df_areas.method == methods[0])\n",
    "        & (df_areas.variant == variants[0])\n",
    "        & (df_areas.transformation == transformations[0])\n",
    "    ]\n",
    "    .iloc[0]\n",
    "    .eu_sum\n",
    ")\n",
    "ax.annotate(\n",
    "    \"$U_\\mathcal{{D}}={0:.2f}$\".format(val),\n",
    "    xy=(0.24, 0.7),\n",
    "    xytext=(0.05, 0.9),\n",
    "    arrowprops=dict(\n",
    "        facecolor=palette[readble_method(methods[0])], alpha=1.0, shrink=0.05\n",
    "    ),\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "# Get values for L_D method 2\n",
    "val = (\n",
    "    df_areas[\n",
    "        (df_areas.dataset == dataset)\n",
    "        & (df_areas.method == methods[1])\n",
    "        & (df_areas.variant == variants[1])\n",
    "        & (df_areas.transformation == transformations[1])\n",
    "    ]\n",
    "    .iloc[0]\n",
    "    .eu_sum\n",
    ")\n",
    "ax.annotate(\n",
    "    \"$U_\\mathcal{{D}}={0:.2f}$\".format(val),\n",
    "    xy=(0.6, 0.65),\n",
    "    xytext=(0.65, 0.42),\n",
    "    arrowprops=dict(\n",
    "        facecolor=palette[readble_method(methods[1])], alpha=1.0, shrink=0.05\n",
    "    ),\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "handles, lables = ax.get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "    h.set_linestyle(\"solid\")\n",
    "ax.legend(handles[1 : 1 + len(methods)], lables[1 : 1 + len(methods)])\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_custom_examples\"\n",
    "plt.subplots_adjust(wspace=0.27)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeYWCdr65Ojg"
   },
   "source": [
    "### kNN with k>=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "wdXY9CEv5X4V",
    "outputId": "74c1bc66-f7fc-4b1c-e1e1-160b7e8952ab"
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# CONFIG 2\n",
    "dataset = \"cifar10\"\n",
    "variants = [f\"measure=cosine, k={k}\" for k in range(1, 11, 2)]\n",
    "methods = [\"knn\"] * len(variants)\n",
    "transformations = [\"efficientnet_b7_tf\"] * len(variants)\n",
    "\n",
    "axes[0].set_title(\"CIFAR10 - EfficientNetB7\")\n",
    "axes[0].set_xlim(0, 1.0)\n",
    "axes[0].set_ylim(0, 0.91)\n",
    "\n",
    "plot_single_axis(\n",
    "    axes[0],\n",
    "    dataset,\n",
    "    methods,\n",
    "    variants,\n",
    "    transformations,\n",
    "    ci=None,\n",
    "    labels_src=\"variant\",\n",
    "    label_fn=lambda x: x.split(\", \")[-1],\n",
    ")\n",
    "\n",
    "# CONFIG 1\n",
    "dataset = \"imdb\"\n",
    "variants = [f\"measure=cosine, k={k}\" for k in range(1, 11, 2)]\n",
    "methods = [\"knn\"] * len(variants)\n",
    "transformations = [\"use\"] * len(variants)\n",
    "\n",
    "axes[1].set_title(\"IMDB - USE\")\n",
    "axes[1].set_xlim(0, 1.0)\n",
    "axes[1].set_ylim(0, 0.51)\n",
    "\n",
    "plot_single_axis(\n",
    "    axes[1],\n",
    "    dataset,\n",
    "    methods,\n",
    "    variants,\n",
    "    transformations,\n",
    "    ci=None,\n",
    "    labels_src=\"variant\",\n",
    "    label_fn=lambda x: x.split(\", \")[-1],\n",
    ")\n",
    "\n",
    "handles, lables = axes.flat[0].get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "f.legend(\n",
    "    handles[1 : 1 + len(methods)],\n",
    "    lables[1 : 1 + len(methods)],\n",
    "    loc=\"upper center\",\n",
    "    ncol=len(methods),\n",
    ")\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_larger_k_fails\"\n",
    "plt.subplots_adjust(wspace=0.27, top=0.78)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNdypATQnBw7"
   },
   "source": [
    "### Example fixed transformation and h-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "ptC-bkEDnBw8",
    "outputId": "7bc4fbac-b789-4de6-aa7d-ab74e868fabc"
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# CONFIG 2\n",
    "dataset = \"cifar10\"\n",
    "variants = [\"measure=cosine, k=1\", \"measure=cosine\"]\n",
    "methods = [\"knn_extrapolate\", \"1nn\"]\n",
    "transformations = [\"raw\", \"raw\"]\n",
    "\n",
    "axes[0].set_title(\"CIFAR10 - RAW\")\n",
    "axes[0].set_xlim(0, 1.0)\n",
    "axes[0].set_ylim(0, 0.91)\n",
    "\n",
    "plot_single_axis(\n",
    "    axes[0], dataset, methods, variants, transformations, ci=None, labels_src=\"method\"\n",
    ")\n",
    "\n",
    "# CONFIG 1\n",
    "dataset = \"cifar10\"\n",
    "variants = [\"measure=cosine, k=1\", \"measure=cosine\"]\n",
    "methods = [\"knn_extrapolate\", \"1nn\"]\n",
    "transformations = [\"efficientnet_b7_tf\"] * len(variants)\n",
    "\n",
    "axes[1].set_title(\"CIFAR10 - EfficientNetB7\")\n",
    "axes[1].set_xlim(0, 1.0)\n",
    "axes[1].set_ylim(0, 0.91)\n",
    "\n",
    "plot_single_axis(\n",
    "    axes[1], dataset, methods, variants, transformations, ci=None, labels_src=\"method\"\n",
    ")\n",
    "\n",
    "handles, lables = axes.flat[0].get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "f.legend(\n",
    "    handles[1 : 1 + len(methods)],\n",
    "    lables[1 : 1 + len(methods)],\n",
    "    loc=\"upper center\",\n",
    "    ncol=len(methods),\n",
    ")\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_example_fixed_values_cifar10\"\n",
    "plt.subplots_adjust(wspace=0.27, top=0.78)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "bl3zFMMxqAw0",
    "outputId": "b7da66b3-a6d1-4f53-9ce8-5126ffb4903b"
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# CONFIG 2\n",
    "dataset = \"imdb\"\n",
    "variants = [\"measure=cosine, k=1\", \"measure=cosine\"]\n",
    "methods = [\"knn_extrapolate\", \"1nn\"]\n",
    "transformations = [\"nnlm50\", \"nnlm50\"]\n",
    "\n",
    "axes[0].set_title(\"IMDB - NNLM-EN (d=50)\")\n",
    "axes[0].set_xlim(0, 1.0)\n",
    "axes[0].set_ylim(0, 0.51)\n",
    "\n",
    "plot_single_axis(\n",
    "    axes[0], dataset, methods, variants, transformations, ci=None, labels_src=\"method\"\n",
    ")\n",
    "\n",
    "# CONFIG 1\n",
    "dataset = \"imdb\"\n",
    "variants = [\"measure=cosine, k=1\", \"measure=cosine\"]\n",
    "methods = [\"knn_extrapolate\", \"1nn\"]\n",
    "transformations = [\"use\"] * len(variants)\n",
    "\n",
    "axes[1].set_title(\"IMDB - USE\")\n",
    "axes[1].set_xlim(0, 1.0)\n",
    "axes[1].set_ylim(0, 0.51)\n",
    "\n",
    "plot_single_axis(\n",
    "    axes[1], dataset, methods, variants, transformations, ci=None, labels_src=\"method\"\n",
    ")\n",
    "\n",
    "handles, lables = axes.flat[0].get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "f.legend(\n",
    "    handles[1 : 1 + len(methods)],\n",
    "    lables[1 : 1 + len(methods)],\n",
    "    loc=\"upper center\",\n",
    "    ncol=len(methods),\n",
    ")\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_example_fixed_values_imdb\"\n",
    "plt.subplots_adjust(wspace=0.27, top=0.78)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbJeNzD05q-6"
   },
   "source": [
    "### LR Classifier vs. 1NN Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "TdNsYBqe5ttv",
    "outputId": "ca108a18-072b-40d8-aa3d-4430e3c57db8"
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(6, 5))\n",
    "\n",
    "# CONFIG\n",
    "dataset = \"yelp\"\n",
    "\n",
    "variants = [\"measure=cosine, k=1\", \"l2=0.0, lr=0.001\", \"l2=0.0, lr=0.001\"]\n",
    "methods = [\"knn\", \"lr_model_0.95\", \"lr_model_0.8\"]\n",
    "transformations = [\"use\"] * len(variants)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set_title(\"YELP - USE\")\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.set_ylim(0, 0.81)\n",
    "\n",
    "plot_single_axis(\n",
    "    ax,\n",
    "    dataset,\n",
    "    methods,\n",
    "    variants,\n",
    "    transformations,\n",
    "    labels_src=\"method\",\n",
    "    use_palet=False,\n",
    "    ci=None,\n",
    "    label_fn=lambda x: readble_method(\"1nn\") if x == \"knn\" else readble_method(x),\n",
    ")\n",
    "\n",
    "handles, lables = ax.get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "f.legend(\n",
    "    handles[1 : 1 + len(methods)],\n",
    "    lables[1 : 1 + len(methods)],\n",
    "    loc=\"upper center\",\n",
    "    ncol=len(methods),\n",
    ")\n",
    "\n",
    "ax.legend([], [], frameon=False)\n",
    "\n",
    "ax2 = plt.axes([0.53, 0.15, 0.35, 0.25])\n",
    "ax2.set_xlim(0.0, 0.1)\n",
    "ax2.set_ylim(0.25, 0.4)\n",
    "plot_single_axis(\n",
    "    ax2,\n",
    "    dataset,\n",
    "    methods,\n",
    "    variants,\n",
    "    transformations,\n",
    "    labels_src=\"method\",\n",
    "    use_palet=False,\n",
    "    ci=None,\n",
    "    label_fn=lambda x: readble_method(\"1nn\") if x == \"knn\" else readble_method(x),\n",
    ")\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.set_xticks([])\n",
    "ax2.set_ylabel(\"\")\n",
    "ax2.set_yticks([])\n",
    "ax2.legend([], [], frameon=False)\n",
    "mark_inset(ax, ax2, loc1=2, loc2=3, fc=\"none\", ec=\"0.5\", ls=\"--\")\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_lr_vs_1nn\"\n",
    "plt.subplots_adjust(wspace=0.2, top=0.78)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyOrnOmfscHO"
   },
   "source": [
    "### SOTA Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_96jHyDszKd"
   },
   "outputs": [],
   "source": [
    "# Common function\n",
    "\n",
    "\n",
    "def filter_by_minquantity_factor(datasets, quantity, factor=\"1.0\"):\n",
    "    print(f\"  Minimizing quantity '{quantity}' on sota with factor '{factor}'\")\n",
    "\n",
    "    if factor == \"1.0\":\n",
    "        df_filter = df_areas[\n",
    "            (df_areas.method.isin(methods_to_evaluate))\n",
    "            & (df_areas.dataset.isin(datasets))\n",
    "        ]\n",
    "    else:\n",
    "        df_filter = df_areas_factors[factor][\n",
    "            (df_areas_factors[factor].method.isin(methods_to_evaluate))\n",
    "            & (df_areas_factors[factor].dataset.isin(datasets))\n",
    "        ]\n",
    "\n",
    "    df_filter = df_filter[\n",
    "        ~(df_filter.method.isin([\"kde_knn_loo\", \"knn\", \"onenn\"]))\n",
    "        | ~(df_filter.variant.str.endswith(\", k=1\"))\n",
    "    ]\n",
    "\n",
    "    df_filter = df_filter.loc[\n",
    "        df_filter.groupby([\"dataset\", \"method\"])[quantity].idxmin()\n",
    "    ]\n",
    "\n",
    "    val_columns = [\n",
    "        \"lowerbound\",\n",
    "        \"upperbound\",\n",
    "        \"el_sum\",\n",
    "        \"eu_sum\",\n",
    "        \"el_bottom\",\n",
    "        \"el_top\",\n",
    "        \"eu_bottom\",\n",
    "        \"eu_top\",\n",
    "    ]\n",
    "\n",
    "    df_csv = df_filter[\n",
    "        [\"dataset\", \"method\", \"variant\", \"transformation\"] + val_columns\n",
    "    ].copy()\n",
    "    df_csv.insert(0, \"minimize_quantity\", quantity)\n",
    "    df_csv.insert(0, \"sota_factor\", factor)\n",
    "\n",
    "    for col in val_columns:\n",
    "        df_csv[col] = df_csv[col].map(lambda x: 0.0 if x < 0 else x)\n",
    "\n",
    "    df_csv.dataset = df_csv.dataset.map(lambda x: x.upper())\n",
    "    df_csv.variant = df_csv.variant.map(shorten_variant)\n",
    "    df_csv.method = df_csv.method.map(readble_method)\n",
    "    df_csv.transformation = df_csv.transformation.map(readble_transformation)\n",
    "\n",
    "    return df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVWIHFOOtOzz",
    "outputId": "9b07f96a-d744-457f-cf0c-4827b1369093"
   },
   "outputs": [],
   "source": [
    "df_csv = pd.concat(\n",
    "    [\n",
    "        filter_by_minquantity_factor(config.keys(), \"el_sum\", \"1.0\"),\n",
    "        filter_by_minquantity_factor(config.keys(), \"eu_sum\", \"1.0\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for factor in [\"0.75\", \"0.90\", \"0.95\", \"1.05\", \"1.10\", \"1.25\"]:\n",
    "    df_csv = pd.concat(\n",
    "        [\n",
    "            df_csv,\n",
    "            filter_by_minquantity_factor(config.keys(), \"el_sum\", factor),\n",
    "            filter_by_minquantity_factor(config.keys(), \"eu_sum\", factor),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "t_80HWPuuApP",
    "outputId": "4eace30f-88f4-4290-c823-476d99c9e8e1"
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "ax = sns.violinplot(\n",
    "    ax=axes[0],\n",
    "    x=\"dataset\",\n",
    "    y=\"el_sum\",\n",
    "    hue=\"method\",\n",
    "    data=df_csv[\n",
    "        (df_csv.minimize_quantity == \"el_sum\")\n",
    "        & df_csv.dataset.isin([\"CIFAR10\", \"CIFAR100\", \"YELP\"])\n",
    "    ],\n",
    "    scale=\"count\",\n",
    ")\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"$L_\\mathcal{D}$\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "\n",
    "ax = sns.violinplot(\n",
    "    ax=axes[1],\n",
    "    x=\"dataset\",\n",
    "    y=\"eu_sum\",\n",
    "    hue=\"method\",\n",
    "    data=df_csv[\n",
    "        (df_csv.minimize_quantity == \"eu_sum\")\n",
    "        & df_csv.dataset.isin([\"CIFAR10\", \"CIFAR100\", \"YELP\"])\n",
    "    ],\n",
    "    scale=\"count\",\n",
    ")\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"$U_\\mathcal{D}$\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "\n",
    "handles, lables = axes.flat[0].get_legend_handles_labels()\n",
    "f.legend(handles, lables, loc=\"upper center\", ncol=4)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_variations_of_sota\"\n",
    "plt.subplots_adjust(wspace=0.27, top=0.78)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPG24tuYX6mF"
   },
   "source": [
    "### Optimal $L_\\mathcal{D}$ and $U_\\mathcal{D}$ - Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLYL667RX_Br"
   },
   "outputs": [],
   "source": [
    "# Common function\n",
    "\n",
    "\n",
    "def plot_single(ax, dataset, quantity, value_type):\n",
    "    print(f\"  Minimizing quantity '{quantity}'\")\n",
    "\n",
    "    # CONFIG\n",
    "    classes = config[dataset][\"classes\"]\n",
    "    sota = config[dataset][\"sota\"]\n",
    "\n",
    "    x = [x / float(10) for x in range(11)]\n",
    "    y_true_upper = [sota + val * ((classes - 1.0) / classes - sota) for val in x]\n",
    "    trivial_lower = 0.0\n",
    "    y_true_lower = [\n",
    "        trivial_lower + val * ((classes - 1.0) / classes - trivial_lower) for val in x\n",
    "    ]\n",
    "\n",
    "    df_filter = df_areas[\n",
    "        (df_areas.method.isin(methods_to_evaluate)) & (df_areas.dataset == dataset)\n",
    "    ]\n",
    "\n",
    "    df_filter = df_filter[\n",
    "        ~(df_filter.method.isin([\"kde_knn_loo\", \"knn\", \"onenn\"]))\n",
    "        | ~(df_filter.variant.str.endswith(\", k=1\"))\n",
    "    ]\n",
    "\n",
    "    df_filter = df_filter.loc[df_filter.groupby(\"method\")[quantity].idxmin()]\n",
    "\n",
    "    df_filter = df_filter[[\"dataset\", \"method\", \"variant\", \"transformation\"]]\n",
    "\n",
    "    df2 = pd.merge(\n",
    "        df_results[df_results.value_type == value_type],\n",
    "        df_filter,\n",
    "        on=[\"dataset\", \"method\", \"variant\", \"transformation\"],\n",
    "        how=\"right\",\n",
    "    )\n",
    "\n",
    "    # Readable name\n",
    "    df2[\"method\"] = df2.method.map(readble_method)\n",
    "\n",
    "    sns.lineplot(x=x, y=y_true_upper, ax=ax)\n",
    "    sns.lineplot(x=x, y=y_true_lower, ax=ax)\n",
    "    ax.lines[-2].set_color(\"Gray\")\n",
    "    ax.lines[-1].set_color(\"Gray\")\n",
    "    ax.lines[-1].set_linestyle(\"--\")\n",
    "    ax = sns.lineplot(\n",
    "        data=df2,\n",
    "        ax=ax,\n",
    "        x=\"noise\",\n",
    "        y=\"value\",\n",
    "        hue=\"method\",\n",
    "        style=\"value_type\",\n",
    "        dashes=dashes,\n",
    "        ci=None,\n",
    "        linewidth=3,\n",
    "        palette=palette,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "HtUl8_zNYHGm",
    "outputId": "9c0c8306-4946-4f9f-c225-7b2046a1f742"
   },
   "outputs": [],
   "source": [
    "# Vision datasets\n",
    "\n",
    "datasets = [\"mnist\", \"cifar10\", \"cifar100\"]\n",
    "ylims = [1.0, 1.0, 1.0]\n",
    "\n",
    "f, axes = plt.subplots(2, len(datasets), figsize=(12, 6), sharex=\"col\")\n",
    "for index, dataset in enumerate(datasets):\n",
    "    print(f\"Running for dataset '{dataset}'\")\n",
    "\n",
    "    x_label = r\"Label noise $\\rho$\"\n",
    "\n",
    "    ax = axes[0][index]\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, ylims[index])\n",
    "    plot_single(ax, dataset, \"el_sum\", \"lowerbound\")\n",
    "    ax.set_title(\"{0}\".format(dataset.upper()))\n",
    "    if index == 0:\n",
    "        ax.set_ylabel(\"Optim. $L_{\\mathcal{D}}(m)$\\n Estimate\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    ax = axes[1][index]\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, ylims[index])\n",
    "    plot_single(ax, dataset, \"eu_sum\", \"upperbound\")\n",
    "    if index == 0:\n",
    "        ax.set_ylabel(\"Optim. $U_{\\mathcal{D}}(m)$\\n Estimate\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(x_label)\n",
    "\n",
    "handles, lables = axes.flat[0].get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "    h.set_linestyle(\"solid\")\n",
    "\n",
    "f.legend(\n",
    "    handles[1 : 1 + len(methods_to_evaluate)],\n",
    "    lables[1 : 1 + len(methods_to_evaluate)],\n",
    "    loc=\"upper center\",\n",
    "    ncol=(len(methods_to_evaluate)) // 2,\n",
    ")\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_lower_upper_vision\"\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.15, top=0.75)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "_ArCiP8bYU0C",
    "outputId": "e8ae6c8e-e9ad-4648-b9f4-2f94e655cbc0"
   },
   "outputs": [],
   "source": [
    "# NLP Datasets\n",
    "\n",
    "datasets = [\"imdb\", \"sst2\", \"yelp\"]\n",
    "ylims = [0.5, 0.5, 0.8]\n",
    "\n",
    "f, axes = plt.subplots(2, len(datasets), figsize=(12, 6), sharex=\"col\")\n",
    "for index, dataset in enumerate(datasets):\n",
    "    print(f\"Running for dataset '{dataset}'\")\n",
    "\n",
    "    x_label = r\"Label noise $\\rho$\"\n",
    "\n",
    "    ax = axes[0][index]\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, ylims[index])\n",
    "    plot_single(ax, dataset, \"el_sum\", \"lowerbound\")\n",
    "    ax.set_title(\"{0}\".format(dataset.upper()))\n",
    "    if index == 0:\n",
    "        ax.set_ylabel(\"Optim. $L_{\\mathcal{D}}(m)$\\n Error\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    ax = axes[1][index]\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, ylims[index])\n",
    "    plot_single(ax, dataset, \"eu_sum\", \"upperbound\")\n",
    "    if index == 0:\n",
    "        ax.set_ylabel(\"Optim. $U_{\\mathcal{D}}(m)$\\n Error\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(x_label)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_lower_upper_nlp\"\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.15, top=0.75)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skIUEaSW736Z"
   },
   "source": [
    "### Optimal $L_\\mathcal{D}$ and $U_\\mathcal{D}$ on raw - Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAXJ6xSr736a"
   },
   "outputs": [],
   "source": [
    "# Common function\n",
    "\n",
    "\n",
    "def plot_single_raw(ax, dataset, quantity, value_type):\n",
    "    print(f\"  Minimizing quantity '{quantity}'\")\n",
    "\n",
    "    # CONFIG\n",
    "    classes = config[dataset][\"classes\"]\n",
    "    sota = config[dataset][\"sota\"]\n",
    "\n",
    "    x = [x / float(10) for x in range(11)]\n",
    "    y_true_upper = [sota + val * ((classes - 1.0) / classes - sota) for val in x]\n",
    "    trivial_lower = 0.0\n",
    "    y_true_lower = [\n",
    "        trivial_lower + val * ((classes - 1.0) / classes - trivial_lower) for val in x\n",
    "    ]\n",
    "\n",
    "    df_filter = df_areas[\n",
    "        (df_areas.method.isin(methods_to_evaluate))\n",
    "        & (df_areas.dataset == dataset)\n",
    "        & (df_areas.transformation == \"raw\")\n",
    "    ]\n",
    "\n",
    "    df_filter = df_filter[\n",
    "        ~(df_filter.method.isin([\"kde_knn_loo\", \"knn\", \"onenn\"]))\n",
    "        | ~(df_filter.variant.str.endswith(\", k=1\"))\n",
    "    ]\n",
    "\n",
    "    df_filter = df_filter.loc[df_filter.groupby(\"method\")[quantity].idxmin()]\n",
    "\n",
    "    df_filter = df_filter[[\"dataset\", \"method\", \"variant\", \"transformation\"]]\n",
    "\n",
    "    df2 = pd.merge(\n",
    "        df_results[df_results.value_type == value_type],\n",
    "        df_filter,\n",
    "        on=[\"dataset\", \"method\", \"variant\", \"transformation\"],\n",
    "        how=\"right\",\n",
    "    )\n",
    "\n",
    "    # Readable name\n",
    "    df2[\"method\"] = df2.method.map(readble_method)\n",
    "\n",
    "    sns.lineplot(x=x, y=y_true_upper, ax=ax)\n",
    "    sns.lineplot(x=x, y=y_true_lower, ax=ax)\n",
    "    ax.lines[-2].set_color(\"Gray\")\n",
    "    ax.lines[-1].set_color(\"Gray\")\n",
    "    ax.lines[-1].set_linestyle(\"--\")\n",
    "    ax = sns.lineplot(\n",
    "        data=df2,\n",
    "        ax=ax,\n",
    "        x=\"noise\",\n",
    "        y=\"value\",\n",
    "        hue=\"method\",\n",
    "        style=\"value_type\",\n",
    "        dashes=dashes,\n",
    "        ci=None,\n",
    "        linewidth=3,\n",
    "        palette=palette,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "IACkhoHS736a",
    "outputId": "a80d941c-0a53-4497-83e2-cf203c2ee736"
   },
   "outputs": [],
   "source": [
    "# Vision datasets\n",
    "\n",
    "datasets = [\"mnist\", \"cifar10\", \"cifar100\"]\n",
    "ylims = [1.0, 1.0, 1.0]\n",
    "\n",
    "f, axes = plt.subplots(2, len(datasets), figsize=(12, 6), sharex=\"col\")\n",
    "for index, dataset in enumerate(datasets):\n",
    "    print(f\"Running for dataset '{dataset}'\")\n",
    "\n",
    "    x_label = r\"Label noise $\\rho$\"\n",
    "\n",
    "    ax = axes[0][index]\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, ylims[index])\n",
    "    plot_single_raw(ax, dataset, \"el_sum\", \"lowerbound\")\n",
    "    ax.set_title(\"{0}\".format(dataset.upper()))\n",
    "    if index == 0:\n",
    "        ax.set_ylabel(\"Optim. $L_{\\mathcal{D}}(m)$\\n Estimate\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    ax = axes[1][index]\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, ylims[index])\n",
    "    plot_single_raw(ax, dataset, \"eu_sum\", \"upperbound\")\n",
    "    if index == 0:\n",
    "        ax.set_ylabel(\"Optim. $U_{\\mathcal{D}}(m)$\\n Estimate\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(x_label)\n",
    "\n",
    "handles, lables = axes.flat[0].get_legend_handles_labels()\n",
    "for h in handles:\n",
    "    h.set_linewidth(3.0)\n",
    "    h.set_alpha(0.7)\n",
    "    h.set_linestyle(\"solid\")\n",
    "\n",
    "f.legend(\n",
    "    handles[1 : 1 + len(methods_to_evaluate)],\n",
    "    lables[1 : 1 + len(methods_to_evaluate)],\n",
    "    loc=\"upper center\",\n",
    "    ncol=(len(methods_to_evaluate)) // 2,\n",
    ")\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "save_filename = f\"{fig_folder}/feebee_lower_upper_raw_vision\"\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.15, top=0.75)\n",
    "f.savefig(\"{}.pdf\".format(save_filename), bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8L2hba-WkzR"
   },
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeiNmDvzmXbY"
   },
   "outputs": [],
   "source": [
    "tbl_folder = \"tables\"\n",
    "if not path.exists(tbl_folder):\n",
    "    os.mkdir(tbl_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BieItDeAXAcJ"
   },
   "outputs": [],
   "source": [
    "# Common function\n",
    "\n",
    "\n",
    "def filter_by_minquantity(datasets, quantity, only_raw=False):\n",
    "    print(f\"  Minimizing quantity '{quantity}'\")\n",
    "\n",
    "    if only_raw:\n",
    "        df_filter = df_areas[\n",
    "            (df_areas.method.isin(methods_to_evaluate))\n",
    "            & (df_areas.dataset.isin(datasets))\n",
    "            & (df_areas.transformation == \"raw\")\n",
    "        ]\n",
    "    else:\n",
    "        df_filter = df_areas[\n",
    "            (df_areas.method.isin(methods_to_evaluate))\n",
    "            & (df_areas.dataset.isin(datasets))\n",
    "        ]\n",
    "\n",
    "    df_filter = df_filter[\n",
    "        ~(df_filter.method.isin([\"kde_knn_loo\", \"knn\", \"onenn\"]))\n",
    "        | ~(df_filter.variant.str.endswith(\", k=1\"))\n",
    "    ]\n",
    "\n",
    "    df_filter = df_filter.loc[\n",
    "        df_filter.groupby([\"dataset\", \"method\"])[quantity].idxmin()\n",
    "    ]\n",
    "\n",
    "    val_columns = [\n",
    "        \"lowerbound\",\n",
    "        \"upperbound\",\n",
    "        \"el_sum\",\n",
    "        \"eu_sum\",\n",
    "        \"el_bottom\",\n",
    "        \"el_top\",\n",
    "        \"eu_bottom\",\n",
    "        \"eu_top\",\n",
    "    ]\n",
    "\n",
    "    df_csv = df_filter[\n",
    "        [\"dataset\", \"method\", \"variant\", \"transformation\"] + val_columns\n",
    "    ].copy()\n",
    "    df_csv.insert(0, \"minimize_quantity\", quantity)\n",
    "\n",
    "    for col in val_columns:\n",
    "        df_csv[col] = df_csv[col].map(lambda x: 0.0 if x < 0 else x)\n",
    "\n",
    "    df_csv.variant = df_csv.variant.map(shorten_variant)\n",
    "    df_csv.method = df_csv.method.map(readble_method)\n",
    "    df_csv.transformation = df_csv.transformation.map(readble_transformation)\n",
    "\n",
    "    return df_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGQMtKi5aR-q"
   },
   "source": [
    "### Optimal $L_\\mathcal{D}$ and $U_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JVNElU2Zx32",
    "outputId": "91bb8752-c31f-4f87-b2bf-8032a526f8c2"
   },
   "outputs": [],
   "source": [
    "df_csv = pd.concat(\n",
    "    [\n",
    "        filter_by_minquantity(config.keys(), \"el_sum\"),\n",
    "        filter_by_minquantity(config.keys(), \"eu_sum\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "MYxRjgshoCZB",
    "outputId": "0cc8cacc-34e4-4874-beef-c0ee559dd9f6"
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "minimizers = [\"el_sum\", \"eu_sum\"]\n",
    "methods_extended = [\n",
    "    \"DE-kNN\",\n",
    "    \"Gaussian KDE\",\n",
    "    \"GHP\",\n",
    "    \"1NN-kNN\",\n",
    "    \"1NN\",\n",
    "    \"kNN\",\n",
    "    \"kNN-LOO\",\n",
    "    \"kNN_Extrapolate\",\n",
    "]\n",
    "\n",
    "final_df = pd.DataFrame(columns=methods_extended)\n",
    "\n",
    "for minimizer in minimizers:\n",
    "    columns = [\"minimize_quantity\", \"method\", minimizer]\n",
    "    new_df = pd.DataFrame(columns=methods_extended)\n",
    "    for dataset, df_grp in df_csv.groupby(\"dataset\"):\n",
    "        df_grp = df_grp[df_grp[\"minimize_quantity\"] == minimizer][[\"method\", minimizer]]\n",
    "        df_grp = df_grp.transpose()\n",
    "        df_grp.reset_index(inplace=True)\n",
    "        df_grp.at[0, \"index\"] = \"Dataset\"\n",
    "        df_grp.at[1, \"index\"] = dataset.upper()\n",
    "        df_grp.columns = df_grp.iloc[0]\n",
    "        df_grp = df_grp[1:]\n",
    "        new_df = pd.concat([new_df, df_grp])\n",
    "\n",
    "    new_df = new_df[[\"Dataset\"] + methods_extended]\n",
    "    new_df.set_index(\"Dataset\", inplace=True)\n",
    "    new_df = new_df.reindex([\"MNIST\", \"CIFAR10\", \"CIFAR100\", \"IMDB\", \"SST2\", \"YELP\"])\n",
    "    final_df = pd.concat([final_df, new_df])\n",
    "final_df.reset_index(drop=False, inplace=True)\n",
    "final_df.rename(\n",
    "    columns={\"index\": \"Dataset\", \"Gaussian KDE\": \"KDE\", \"kNN_Extrapolate\": \"kNN_Ext\"},\n",
    "    inplace=True,\n",
    ")\n",
    "display(final_df)\n",
    "\n",
    "with open(f\"{tbl_folder}/l_d_and_u_d.txt\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[t!]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\n",
    "        \"\\\\caption{$L_{\\cD}(m)$ and $U_{\\cD}(m)$: The optimal values per method.}\\n\"\n",
    "    )\n",
    "    f.write(\"\\\\label{tbl:el_eu}\\n\")\n",
    "    f.write(\"\\\\small\\n\")\n",
    "    f.write(final_df.to_latex(index=False, na_rep=\"-\"))\n",
    "    f.write(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_Mc1dddbG4A"
   },
   "source": [
    "### $L_\\mathcal{D}$ vs. $\\ell_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_ugB9hdafur",
    "outputId": "4a9098d3-4f10-4fc0-b978-cfc8be9df329"
   },
   "outputs": [],
   "source": [
    "df_csv = pd.concat(\n",
    "    [\n",
    "        filter_by_minquantity(config.keys(), \"lowerbound\"),\n",
    "        filter_by_minquantity(config.keys(), \"el_sum\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "OU8WPPyVbMWm",
    "outputId": "94c21b1d-3904-4659-a2bf-5ba7bb51fb19"
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "columns = [\n",
    "    \"minimize_quantity\",\n",
    "    \"method\",\n",
    "    \"variant\",\n",
    "    \"transformation\",\n",
    "    \"lowerbound\",\n",
    "    \"el_sum\",\n",
    "]\n",
    "columns_for_latex = [\"method\", \"delta\"]\n",
    "methods_extended = [\n",
    "    \"DE-kNN\",\n",
    "    \"Gaussian KDE\",\n",
    "    \"GHP\",\n",
    "    \"1NN-kNN\",\n",
    "    \"1NN\",\n",
    "    \"kNN\",\n",
    "    \"kNN-LOO\",\n",
    "    \"kNN_Extrapolate\",\n",
    "]\n",
    "new_df = pd.DataFrame(columns=methods_extended)\n",
    "for dataset, df_grp in df_csv.groupby(\"dataset\"):\n",
    "    df_grp[\"delta\"] = pd.Series(dtype=float)\n",
    "    for method, df_method in df_grp.groupby(\"method\"):\n",
    "        idx = df_method.index.to_list()\n",
    "        df_grp.at[idx[0], \"delta\"] = (\n",
    "            df_method.at[idx[0], \"el_sum\"] - df_method.at[idx[1], \"el_sum\"]\n",
    "        )\n",
    "    df_to_latex = df_grp[df_grp[\"minimize_quantity\"] == \"lowerbound\"][columns_for_latex]\n",
    "    df_to_latex = df_to_latex.transpose()\n",
    "    df_to_latex.reset_index(inplace=True)\n",
    "    df_to_latex.at[0, \"index\"] = \"dataset\"\n",
    "    df_to_latex.at[1, \"index\"] = dataset.upper()\n",
    "\n",
    "    df_to_latex.columns = df_to_latex.iloc[0]\n",
    "    df_to_latex = df_to_latex[1:]\n",
    "    new_df = pd.concat([new_df, df_to_latex])\n",
    "\n",
    "new_df = new_df[[\"dataset\"] + methods_extended]\n",
    "new_df.set_index(\"dataset\", inplace=True)\n",
    "new_df = new_df.reindex([\"MNIST\", \"CIFAR10\", \"CIFAR100\", \"IMDB\", \"SST2\", \"YELP\"])\n",
    "new_df.reset_index(drop=False, inplace=True)\n",
    "new_df.rename(\n",
    "    columns={\"dataset\": \"Dataset\", \"Gaussian KDE\": \"KDE\", \"kNN_Extrapolate\": \"kNN_Ext\"},\n",
    "    inplace=True,\n",
    ")\n",
    "display(new_df)\n",
    "\n",
    "with open(f\"{tbl_folder}/lower_vs_l_d.txt\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[t!]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\n",
    "        \"\\\\caption{The difference between the \\\\emph{optimal} $L_{\\\\cD}(m)$ and the $L_{\\\\cD}(m)$ calculated for hyper-parameters and transformations that minimize $l_{\\\\cD,m}(0)$.}\\n\"\n",
    "    )\n",
    "    f.write(\"\\\\label{tbl:min_l_vs_min_el}\\n\")\n",
    "    f.write(\"\\\\small\\n\")\n",
    "    f.write(new_df.to_latex(index=False, na_rep=\"-\"))\n",
    "    f.write(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBA-HcthkasS"
   },
   "source": [
    "### knn with k>=1 and LR Classifier vs. 1NN Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "hR5yTFuykab2",
    "outputId": "a6c46819-447e-401b-c70f-003fca7efd0d"
   },
   "outputs": [],
   "source": [
    "def filter_fn(row):\n",
    "    for i, m in enumerate(methods):\n",
    "        if (\n",
    "            (row.method == m)\n",
    "            and (row.transformation == transformations[i])\n",
    "            and (row.variant == variants[i])\n",
    "        ):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# CONFIG 1\n",
    "dataset = \"yelp\"\n",
    "variants = [\"measure=cosine, k=1\", \"l2=0.0, lr=0.001\", \"l2=0.0, lr=0.001\"]\n",
    "methods = [\"knn\", \"lr_model_0.95\", \"lr_model_0.8\"]\n",
    "transformations = [\"use\"] * len(variants)\n",
    "\n",
    "df_filter1 = df_areas[\n",
    "    (df_areas.method.isin(methods))\n",
    "    & (df_areas.dataset == dataset)\n",
    "    & (df_areas.variant.isin(variants))\n",
    "    & (df_areas.transformation.isin(transformations))\n",
    "]\n",
    "df_filter1 = df_filter1[df_filter1.apply(filter_fn, axis=1)].copy()\n",
    "\n",
    "# CONFIG 2\n",
    "dataset = \"imdb\"\n",
    "variants = [f\"measure=cosine, k={k}\" for k in range(1, 11, 2)]\n",
    "methods = [\"knn\"] * len(variants)\n",
    "transformations = [\"use\"] * len(variants)\n",
    "\n",
    "df_filter2 = df_areas[\n",
    "    (df_areas.method.isin(methods))\n",
    "    & (df_areas.dataset == dataset)\n",
    "    & (df_areas.variant.isin(variants))\n",
    "    & (df_areas.transformation.isin(transformations))\n",
    "]\n",
    "df_filter2 = df_filter2[df_filter2.apply(filter_fn, axis=1)].copy()\n",
    "\n",
    "# CONFIG 3\n",
    "dataset = \"cifar10\"\n",
    "variants = [f\"measure=cosine, k={k}\" for k in range(1, 11, 2)]\n",
    "methods = [\"knn\"] * len(variants)\n",
    "transformations = [\"efficientnet_b7_tf\"] * len(variants)\n",
    "\n",
    "df_filter3 = df_areas[\n",
    "    (df_areas.method.isin(methods))\n",
    "    & (df_areas.dataset == dataset)\n",
    "    & (df_areas.variant.isin(variants))\n",
    "    & (df_areas.transformation.isin(transformations))\n",
    "]\n",
    "df_filter3 = df_filter3[df_filter3.apply(filter_fn, axis=1)].copy()\n",
    "\n",
    "filtered_df = pd.concat([df_filter1, df_filter2, df_filter3])\n",
    "\n",
    "\n",
    "def newmethod(row):\n",
    "    if row.method == \"knn\":\n",
    "        k = row.variant.split(\"k=\")[-1]\n",
    "        return f\"{k}NN\"\n",
    "    return readble_method(row.method)\n",
    "\n",
    "\n",
    "filtered_df.method = filtered_df.apply(newmethod, axis=1)\n",
    "filtered_df.dataset = filtered_df.dataset.apply(lambda x: x.upper())\n",
    "filtered_df.transformation = filtered_df.transformation.apply(readble_transformation)\n",
    "\n",
    "# filtered_df.set_index('method', inplace=True)\n",
    "filtered_df = filtered_df[\n",
    "    [\"dataset\", \"method\", \"transformation\", \"eu_top\", \"el_sum\", \"el_top\", \"el_bottom\"]\n",
    "]\n",
    "\n",
    "filtered_df.rename(\n",
    "    columns={\n",
    "        \"dataset\": \"Dataset\",\n",
    "        \"method\": \"Method\",\n",
    "        \"transformation\": \"Transformation\",\n",
    "        \"el_sum\": \"$L_{\\cD}(m)$\",\n",
    "        \"el_bottom\": \"$L_{\\cD,\\triangleleft}(m)$\",\n",
    "        \"el_top\": \"$L_{\\cD,\\triangleright}(m)$\",\n",
    "        \"eu_sum\": \"$U_{\\cD}(m)$\",\n",
    "        \"eu_bottom\": \"$U_{\\cD,\\triangleleft}(m)$\",\n",
    "        \"eu_top\": \"$U_{\\cD,\\triangleright}(m)$\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "filtered_df.sort_values(by=[\"Dataset\", \"Method\"], inplace=True)\n",
    "display(filtered_df)\n",
    "\n",
    "with open(f\"{tbl_folder}/lr_vs_1nn_and_knn_gteq_1.txt\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[h!]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\n",
    "        \"\\\\caption{Impact of $k > 1$ and LR Model with different constants vs. 1NN.}\\n\"\n",
    "    )\n",
    "    f.write(\"\\\\label{tbl:lr_vs_1nn_and_k_gteq_1}\\n\")\n",
    "    f.write(\"\\\\small\\n\")\n",
    "    f.write(filtered_df.to_latex(index=False, na_rep=\"-\", escape=False))\n",
    "    f.write(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBYwpZ1-80Zu"
   },
   "source": [
    "### Optimal $L_\\mathcal{D}$ and $U_\\mathcal{D}$ on raw - Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSL-_tIq80Z9",
    "outputId": "89d273f5-d86a-4a5e-dcf5-dd614816b405"
   },
   "outputs": [],
   "source": [
    "df_csv = pd.concat(\n",
    "    [\n",
    "        filter_by_minquantity(config.keys(), \"el_sum\", only_raw=True),\n",
    "        filter_by_minquantity(config.keys(), \"eu_sum\", only_raw=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "LXfmvaOL80Z-",
    "outputId": "7336eefb-5665-4408-aaf4-a5207e279878"
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "minimizers = [\"el_sum\", \"eu_sum\"]\n",
    "methods_extended = [\n",
    "    \"DE-kNN\",\n",
    "    \"Gaussian KDE\",\n",
    "    \"GHP\",\n",
    "    \"1NN-kNN\",\n",
    "    \"1NN\",\n",
    "    \"kNN\",\n",
    "    \"kNN-LOO\",\n",
    "    \"kNN_Extrapolate\",\n",
    "]\n",
    "\n",
    "final_df = pd.DataFrame(columns=methods_extended)\n",
    "\n",
    "for minimizer in minimizers:\n",
    "    columns = [\"minimize_quantity\", \"method\", minimizer]\n",
    "    new_df = pd.DataFrame(columns=methods_extended)\n",
    "    for dataset, df_grp in df_csv.groupby(\"dataset\"):\n",
    "        df_grp = df_grp[df_grp[\"minimize_quantity\"] == minimizer][[\"method\", minimizer]]\n",
    "        df_grp = df_grp.transpose()\n",
    "        df_grp.reset_index(inplace=True)\n",
    "        df_grp.at[0, \"index\"] = \"Dataset\"\n",
    "        df_grp.at[1, \"index\"] = dataset.upper()\n",
    "        df_grp.columns = df_grp.iloc[0]\n",
    "        df_grp = df_grp[1:]\n",
    "        new_df = pd.concat([new_df, df_grp])\n",
    "\n",
    "    new_df = new_df[[\"Dataset\"] + methods_extended]\n",
    "    new_df.set_index(\"Dataset\", inplace=True)\n",
    "    new_df = new_df.reindex([\"MNIST\", \"CIFAR10\", \"CIFAR100\"])\n",
    "    final_df = pd.concat([final_df, new_df])\n",
    "final_df.reset_index(drop=False, inplace=True)\n",
    "final_df.rename(\n",
    "    columns={\"index\": \"Dataset\", \"Gaussian KDE\": \"KDE\", \"kNN_Extrapolate\": \"kNN_Ext\"},\n",
    "    inplace=True,\n",
    ")\n",
    "display(final_df)\n",
    "\n",
    "with open(f\"{tbl_folder}/l_d_and_u_d_raw_vision.txt\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[t!]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\n",
    "        \"\\\\caption{$L_{\\cD}(m)$ and $U_{\\cD}(m)$: The optimal values per method.}\\n\"\n",
    "    )\n",
    "    f.write(\"\\\\label{tbl:el_eu}\\n\")\n",
    "    f.write(\"\\\\small\\n\")\n",
    "    f.write(final_df.to_latex(index=True, na_rep=\"-\"))\n",
    "    f.write(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPCa6-PdnMNo"
   },
   "source": [
    "### Optimal $L_{\\mathcal{D}}$ and $U_{\\mathcal{D}}$ per dataset - Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHrkkJx-bTtd",
    "outputId": "a1c13431-86e6-4505-d93d-efd331ea0111"
   },
   "outputs": [],
   "source": [
    "df_csv = pd.concat(\n",
    "    [\n",
    "        filter_by_minquantity(config.keys(), \"el_sum\"),\n",
    "        filter_by_minquantity(config.keys(), \"eu_sum\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6A6YvzrlnJ0V",
    "outputId": "86b71b67-e0d4-4e32-a190-eb6c60f2611b"
   },
   "outputs": [],
   "source": [
    "datasets = config.keys()\n",
    "\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "minimizers = [\"el\", \"eu\"]\n",
    "with open(f\"{tbl_folder}/optimal_l_d_u_d_tables.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "# Manually escape stuff\n",
    "df_csv.variant = df_csv.variant.apply(lambda x: x.replace(\"squared_l2\", \"squared\\_l2\"))\n",
    "df_csv.method = df_csv.method.apply(\n",
    "    lambda x: x.replace(\"kNN_Extrapolate\", \"kNN\\_Extrapolate\")\n",
    ")\n",
    "\n",
    "final_columns_L = [\n",
    "    \"Method\",\n",
    "    \"Variant\",\n",
    "    \"Transformation\",\n",
    "    \"$L_{\\cD}(m)$\",\n",
    "    \"$L_{\\cD,\\triangleleft}(m)$\",\n",
    "    \"$L_{\\cD,\\triangleright}(m)$\",\n",
    "]\n",
    "final_columns_U = [\n",
    "    \"Method\",\n",
    "    \"Variant\",\n",
    "    \"Transformation\",\n",
    "    \"$U_{\\cD}(m)$\",\n",
    "    \"$U_{\\cD,\\triangleleft}(m)$\",\n",
    "    \"$U_{\\cD,\\triangleright}(m)$\",\n",
    "]\n",
    "for minimizer in minimizers:\n",
    "    columns = [\n",
    "        \"minimize_quantity\",\n",
    "        \"method\",\n",
    "        \"variant\",\n",
    "        \"transformation\",\n",
    "        minimizer + \"_sum\",\n",
    "        minimizer + \"_bottom\",\n",
    "        minimizer + \"_top\",\n",
    "    ]\n",
    "    for dataset in datasets:\n",
    "        df_grp = df_csv[df_csv.dataset == dataset].sort_values(minimizer + \"_sum\")\n",
    "        print(\"======================\")\n",
    "        print(f\"Minimize {minimizer} for Dataset: {dataset}\")\n",
    "        df_grp = df_grp[df_grp[\"minimize_quantity\"] == minimizer + \"_sum\"][columns]\n",
    "        df_grp.rename(\n",
    "            columns={\n",
    "                \"method\": \"Method\",\n",
    "                \"variant\": \"Variant\",\n",
    "                \"transformation\": \"Transformation\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        if minimizer == \"el\":\n",
    "            df_grp.rename(\n",
    "                columns={\n",
    "                    minimizer + \"_sum\": \"$L_{\\cD}(m)$\",\n",
    "                    minimizer + \"_bottom\": \"$L_{\\cD,\\triangleleft}(m)$\",\n",
    "                    minimizer + \"_top\": \"$L_{\\cD,\\triangleright}(m)$\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "        else:\n",
    "            df_grp.rename(\n",
    "                columns={\n",
    "                    minimizer + \"_sum\": \"$U_{\\cD}(m)$\",\n",
    "                    minimizer + \"_bottom\": \"$U_{\\cD,\\triangleleft}(m)$\",\n",
    "                    minimizer + \"_top\": \"$U_{\\cD,\\triangleright}(m)$\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "        display(df_grp)\n",
    "        with open(f\"{tbl_folder}/optimal_l_d_u_d_tables.txt\", \"a\") as f:\n",
    "            f.write(\"\\\\begin{table}[t!]\\n\")\n",
    "            f.write(\"\\\\centering\\n\")\n",
    "            if minimizer == \"el\":\n",
    "                f.write(\"\\\\caption{\" + dataset.upper() + \" - Optimal $L_{\\\\cD}(m)$}.\\n\")\n",
    "            else:\n",
    "                f.write(\"\\\\caption{\" + dataset.upper() + \" - Optimal $U_{\\\\cD}(m)$}.\\n\")\n",
    "            f.write(\"\\\\label{tbl:\" + dataset + \"_optimal_\" + minimizer + \"}\\n\")\n",
    "            f.write(\"\\\\small\\n\")\n",
    "            if minimizer == \"el\":\n",
    "                f.write(\n",
    "                    df_grp[final_columns_L].to_latex(\n",
    "                        index=False, na_rep=\"-\", escape=False\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                f.write(\n",
    "                    df_grp[final_columns_U].to_latex(\n",
    "                        index=False, na_rep=\"-\", escape=False\n",
    "                    )\n",
    "                )\n",
    "            f.write(\"\\\\end{table}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FeeBee Analysis",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
